{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"smilestyle_dataset.tsv\", sep=\"\\t\")\n",
    "\n",
    "# wide -> long 형식으로 변환 (열 이름 = 스타일 → 하나의 열로 변환)\n",
    "df_long = df.melt(var_name=\"style\", value_name=\"sentence\")\n",
    "\n",
    "# 라벨 인코딩\n",
    "le = LabelEncoder()\n",
    "df_long['label'] = le.fit_transform(df_long['style'])  # 스타일을 숫자로 변환\n",
    "df_long = df_long.dropna(subset=[\"sentence\"]).reset_index(drop=True)\n",
    "\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# 확인\n",
    "print(df_long)\n",
    "print(\"라벨 개수:\", num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")\n",
    "\n",
    "# 토크나이즈 함수 수정 (sentence 열 사용)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# 8:2로 나누기 (라벨 비율 유지, 재현성 있는 분할)\n",
    "train_df, val_df = train_test_split(\n",
    "    df_long,\n",
    "    test_size=0.2,\n",
    "    stratify=df_long[\"label\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Hugging Face Dataset 객체로 변환\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "# 토크나이징\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train = tokenized_train.rename_column(\"label\", \"labels\")\n",
    "tokenized_val = tokenized_val.rename_column(\"label\", \"labels\")\n",
    "\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_val.set_format(\"torch\")\n",
    "\n",
    "print(tokenized_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/kcbert-base\", num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"ToneDetect_model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
