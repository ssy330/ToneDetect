# app.py (ë³´ì™„ë³¸)

import os, sys, uuid, glob, re
import torch, pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

from collections import defaultdict, Counter
from flask import Flask, render_template, request
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì—¬ê¸°ì— LDAìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from konlpy.tag import Okt
from gensim import corpora
from gensim.models import LdaModel


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì›Œë“œí´ë¼ìš°ë“œ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€
from wordcloud import WordCloud

sys.path.append(os.path.join(os.getcwd(), "ì „ì²˜ë¦¬"))

# ì „ì²˜ë¦¬ ëª¨ë“ˆ import
from initial    import run_initial      # raw íŒŒì¼ ì½ê¸° + ê¸°ë³¸ ì „ì²˜ë¦¬
from emoticon   import run_emoticon
from clean      import run_clean        # ì¼ë°˜ í…ìŠ¤íŠ¸ í´ë¦°ì§•
from chat       import run_chat, full_preprocess # ì¹´í†¡ ë§íˆ¬Â·ì¶•ì•½ì–´ ì²˜ë¦¬
from merge      import run_merge        # í™”ìë³„ë¡œ flatten + ìµœì¢… í•©ì¹˜ê¸°

# âœ… ì§„í–‰ë¥  ì €ì¥ìš© (ì „ì—­)
progress_data = {
    "progress": 0
}

plt.rcParams['font.family'] = 'AppleGothic'

# Flask ì•± ìƒì„±
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['GRAPH_FOLDER'] = 'static'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì›Œë“œí´ë¼ìš°ë“œìš© ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mac: ê¸°ë³¸ AppleGothic, Windows: 'C:/Windows/Fonts/malgun.ttf' ë“± í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
FONT_PATH = '/Library/Fonts/AppleGothic.ttf'

def generate_topic_wordclouds(lda_model, dictionary, num_topics=5, topn=30):
    """
    lda_model: gensim.models.LdaModel ê°ì²´
    dictionary: LDA í•™ìŠµì— ì‚¬ìš©ëœ Gensim Dictionary
    num_topics: ì›Œë“œí´ë¼ìš°ë“œë¡œ ë§Œë“¤ í† í”½ ê°œìˆ˜
    topn: í† í”½ë³„ ìƒìœ„ ëª‡ ê°œ ë‹¨ì–´ë¥¼ ì›Œë“œí´ë¼ìš°ë“œì— ë°˜ì˜í• ì§€
    ë°˜í™˜ê°’: ë§Œë“  ì´ë¯¸ì§€ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['topic_1.png', 'topic_2.png', ...])
    """
    # 'static/wordclouds' í´ë”ë¥¼ ë§Œë“¤ì–´ë‘ê³ , ê·¸ê³³ì— ì´ë¯¸ì§€ë¥¼ ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤.
    wc_folder = os.path.join(app.config['GRAPH_FOLDER'], 'wordclouds')
    os.makedirs(wc_folder, exist_ok=True)

    filenames = []
    for topic_id in range(num_topics):
        # ê° í† í”½ì—ì„œ topn ë‹¨ì–´+ê°€ì¤‘ì¹˜ ì¶”ì¶œ
        topic_terms = lda_model.show_topic(topic_id, topn=topn)
        # ì˜ˆ: [("ë‹¨ì–´1", 0.05), ("ë‹¨ì–´2", 0.03), ...]
        freq_dict = {word: float(weight) for word, weight in topic_terms}

        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        wc = WordCloud(
            background_color='white',
            font_path=FONT_PATH,
            width=800,
            height=400
        ).generate_from_frequencies(freq_dict)

        # íŒŒì¼ëª… ì˜ˆì‹œ: 'topic_1.png', 'topic_2.png', ...
        file_name = f"topic_{topic_id+1}.png"
        save_path = os.path.join(wc_folder, file_name)

        # pyplot ì—†ì´ ì§ì ‘ ì €ì¥
        wc.to_file(save_path)
        filenames.append(os.path.join('wordclouds', file_name))  # í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  ê²½ë¡œ (static/wordclouds/...)
    return filenames

# ëª¨ë¸ ë¡œë“œ
ADAPTER_PATH = "Models/ToneDetect_adapter"
BASE_MODEL_NAME = "beomi/kcbert-base"

tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)
base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=5)
model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)
model.eval()

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict_style(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        pred_class = torch.argmax(logits, dim=1).item()
    return pred_class

# ë¼ë²¨ ë§¤í•‘
label_map = {
    0: "chat_emoticon(ì´ëª¨í‹°ì½˜ ìì£¼ ì“°ëŠ” ë§íˆ¬)",
    1: "elder_speech(ì–´ë¥´ì‹  ë§íˆ¬)",
    2: "formal(ê²©ì‹ìˆëŠ” ë§íˆ¬)",
    3: "informal(ì¹œê·¼í•œ ë§íˆ¬)",
    4: "soft_polite(ë¶€ë“œëŸ½ê³  ìƒëƒ¥í•œ ë§íˆ¬)"
}

# ë£¨íŠ¸ í˜ì´ì§€
@app.route('/', methods=['GET', 'POST'])
def index():
    table_html = None
    top_styles = None
    graph_filename = None
    speaker_stats = None
    lda_topics    = None  # LDA í† í”½ ê²°ê³¼ë¥¼ ë‹´ì„ ë³€ìˆ˜
    wc_filenames   = None  # ì›Œë“œí´ë¼ìš°ë“œ ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸


    if request.method == 'POST':
        file = request.files['file']
        if file.filename == '':
            return render_template('index.html', error="íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")

        filepath = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
        file.save(filepath)
        
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì „ì— txt íŒŒì¼ì¸ì§€ ì²´í¬
        if not filepath.endswith('.txt'):
            return render_template('index.html', error="KakaoTalk í…ìŠ¤íŠ¸(.txt) íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤!")
        
        ### âœ… âœ… ê¸°ì¡´ ê·¸ë˜í”„ ì‚­ì œ (ë§¤ë²ˆ ë¶„ì„ ì‹œì‘ ì‹œ!)
        old_graphs = glob.glob(os.path.join(app.config['GRAPH_FOLDER'], "*.png"))
        for old_file in old_graphs:
            os.remove(old_file)
            
        # (2) static/wordclouds í´ë”ê°€ ìˆë‹¤ë©´, ê·¸ ì•ˆì˜ PNGë„ ì „ë¶€ ì‚­ì œ
        wc_folder = os.path.join(app.config['GRAPH_FOLDER'], 'wordclouds')
        if os.path.isdir(wc_folder):
            old_wcs = glob.glob(os.path.join(wc_folder, "*.png"))
            for old_wc in old_wcs:
                os.remove(old_wc)
            
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰(ë‹¨ê³„ë³„ë¡œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ğŸ”¸ğŸ”¸ ë‹¨ê³„ë³„ í˜¸ì¶œ ì‹œì‘ ğŸ”¸ğŸ”¸

        msgs = run_initial(filepath)
        msgs = run_emoticon(msgs) 
        # msgs = run_emotion(msgs)
        msgs = run_clean(msgs)
        print("â–¶ run_clean í›„ sample msg:", msgs[0])
        msgs = run_chat(msgs)
            
        # âœ… ë¶„ì„ ì‹œì‘ ì‹œ ì§„í–‰ë¥  ì´ˆê¸°í™”
        progress_data["progress"] = 0

        # ë¶„ì„
        speaker_style_counts = defaultdict(lambda: defaultdict(int))
        total_msgs = len(msgs)

        for idx, msg in enumerate(msgs):
            speaker = msg['speaker']
            text = msg['cleaned_text']
            pred = predict_style(text)
            style_name = label_map[pred]
            speaker_style_counts[speaker][style_name] += 1

            # âœ… ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_data["progress"] = int((idx + 1) / total_msgs * 100)

        # DataFrame ë³€í™˜
        data = []
        top_styles = {}
        for speaker, style_counts in speaker_style_counts.items():
            row = {'speaker': speaker}
            row.update(style_counts)
            data.append(row)

            # ğŸŸ¢ ê°€ì¥ ë§ì´ ì‚¬ìš©í•œ ë§íˆ¬
            if style_counts:
                top_style = max(style_counts.items(), key=lambda x: x[1])[0]
                top_styles[speaker] = top_style
            else:
                top_styles[speaker] = "ë°ì´í„° ì—†ìŒ"

        # 1ï¸âƒ£ ì›ë³¸ DataFrame ìœ ì§€
        df = pd.DataFrame(data).fillna(0)

        # 2ï¸âƒ£ í‘œìš© ë³µì‚¬ë³¸ ë”°ë¡œ ë§Œë“¤ê¸°
        df_html = df.copy()

        html_columns = []
        for col in df_html.columns:
            if col == 'speaker':
                html_columns.append('speaker')
            else:
                eng, kor = col.split('(')
                kor = kor.rstrip(')')
                html_columns.append(f"{eng}<br>({kor})")

        df_html.columns = html_columns
        table_html = df_html.to_html(classes='data', index=False, escape=False)
        
        # 3ï¸âƒ£ ê·¸ë˜í”„ìš© â†’ ì›ë³¸ df ì‚¬ìš©
        df.set_index('speaker', inplace=True)

        # ğŸŸ¢ ê·¸ë˜í”„ ì €ì¥ ì¤€ë¹„
        os.makedirs(app.config['GRAPH_FOLDER'], exist_ok=True)
        graph_filename = f"{uuid.uuid4().hex}.png"
        graph_path = os.path.join(app.config['GRAPH_FOLDER'], graph_filename)

        # 3ï¸âƒ£ ê·¸ë˜í”„ìš© â†’ ì›ë³¸ df ì‚¬ìš©
        df.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='tab20')
        plt.title("ğŸ“Š í™”ìë³„ ë§íˆ¬ ìŠ¤íƒ€ì¼ ë¶„í¬ (Stacked Bar)", fontsize=14)
        plt.xlabel("í™”ì", fontsize=12)
        plt.ylabel("ë¬¸ì¥ ìˆ˜", fontsize=12)
        plt.xticks(rotation=30)
        plt.legend(title='ë§íˆ¬ ìŠ¤íƒ€ì¼', bbox_to_anchor=(1.05, 1), loc='upper left')
        plt.tight_layout()
        plt.savefig(graph_path)
        plt.close()
        
        
        # âœ… ğŸ”¥ ê°ì • ë¬¸ìì—´ / ì´ëª¨í‹°ì½˜ ë¶„ì„ìš© speaker_stats ìƒì„±
        speaker_emotion_counter = defaultdict(Counter)
        speaker_emotion_examples = defaultdict(lambda: defaultdict(list))

        speaker_emo_counter = defaultdict(Counter)
        speaker_emo_examples = defaultdict(lambda: defaultdict(list))

        for item in msgs:
            speaker = item["speaker"]
            
            # â˜… ì˜ˆì‹œ ë¬¸ì¥ì€ ë°˜ë“œì‹œ â€œì›ë¬¸(original_text)â€ì„ ì‚¬ìš©í•´ì•¼ ì´ëª¨í‹°ì½˜/ì´ëª¨ì§€ê°€ ë³´ì…ë‹ˆë‹¤.
            example_text = item.get("original_text", "")

            # ê°ì • ë¬¸ìì—´
            already_added_chunks = set()
            for chunk_list in item.get("emotion_chunks", {}).values():
                for chunk in chunk_list:
                    speaker_emotion_counter[speaker][chunk] += 1
                    if chunk not in already_added_chunks:
                        if len(speaker_emotion_examples[speaker][chunk]) < 3:
                            speaker_emotion_examples[speaker][chunk].append(example_text)
                        already_added_chunks.add(chunk)

            # ì´ëª¨í‹°ì½˜
            already_added_emoticons = set()
            # run_emoticonì—ì„œ ë½‘ì•„ ë‘” â€œìˆœìˆ˜ í† í°â€ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            for emo in item.get("extracted_emoticons", []):
                speaker_emo_counter[speaker][emo] += 1
                if emo not in already_added_emoticons:
                    if len(speaker_emo_examples[speaker][emo]) < 3:
                        speaker_emo_examples[speaker][emo].append(example_text)
                    already_added_emoticons.add(emo)

        # âœ… speaker_stats ë”•ì…”ë„ˆë¦¬ êµ¬ì„±
        speaker_stats = {}

        for speaker in sorted(set(speaker_emotion_counter) | set(speaker_emo_counter)):
            speaker_stats[speaker] = {
                "emotion_chunks": [],
                "extracted_emoticons": []
            }

            # ê°ì • ë¬¸ìì—´
            top_chunks = speaker_emotion_counter[speaker].most_common(3)
            for chunk, count in top_chunks:
                speaker_stats[speaker]["emotion_chunks"].append({
                    "chunk": chunk,
                    "count": count,
                    "examples": speaker_emotion_examples[speaker][chunk]
                })

            # ì´ëª¨í‹°ì½˜
            top_emoticons = speaker_emo_counter[speaker].most_common(3)
            for emo, count in top_emoticons:
                speaker_stats[speaker]["extracted_emoticons"].append({
                    "emoji": emo,
                    "count": count,
                    "examples": speaker_emo_examples[speaker][emo]
                })
            
        # âœ… ë””ë²„ê·¸ ì¶œë ¥
        print("=== speaker_stats ìµœì¢… ê²°ê³¼ ===")
        import pprint
        pprint.pprint(speaker_stats)
        
        merged_msgs = run_merge(msgs)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ run_merge ì§í›„ ë””ë²„ê¹… ì½”ë“œ ì‹œì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print("â–¶ run_merge() í›„ merged_msgs ìƒ˜í”Œ (ì´ ê°œìˆ˜:", len(merged_msgs), "ê°œ)")

        import pprint
        pprint.pprint(merged_msgs[:5])

        print("\nâ–¶ run_merge() í›„ merged_msgs ê° í•­ëª© ìƒì„¸ë³´ê¸° (ìµœì´ˆ 5ê°œ)")
        for i, m in enumerate(merged_msgs[:5], start=1):
            print(f"--- ë©”ì‹œì§€ #{i} ---")
            print(f"timestamp : {m.get('timestamp')}")
            print(f"speaker   : {m.get('speaker')}")
            print(f"text      : {m.get('text')}")
            remaining = {k: v for k, v in m.items() if k not in ['timestamp','speaker','text']}
            print("ê·¸ ì™¸ í•„ë“œ:", remaining)
            print()
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ run_merge ì§í›„ ë””ë²„ê¹… ì½”ë“œ ë â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # (1) â€œìµœì¢… ì •ì œëœ ë¬¸ì¥â€ ë¦¬ìŠ¤íŠ¸ ìƒì„± (run_merge ì´í›„)
        texts = [
            item["text"]
            for item in merged_msgs
            if item.get("text") and item["text"].strip()
        ]

        # (2) í˜•íƒœì†Œ ë¶„ì„ê¸°ë¡œ ê° ë¬¸ì¥ì—ì„œ ëª…ì‚¬ë§Œ ì¶”ì¶œ â†’ í† í°í™”ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
        okt = Okt()
        tokenized_texts = [okt.nouns(txt) for txt in texts]

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ LDA ì‹¤í–‰ ì „ ì˜ˆì™¸ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # tokenized_texts ìì²´ê°€ ë¹„ì–´ ìˆê±°ë‚˜,
        # tokenized_texts ë‚´ì˜ ëª¨ë“  ìš”ì†Œê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¼ ë•Œ LDAë¥¼ ì‹¤í–‰í•˜ë©´ ì˜¤ë¥˜ ë°œìƒí•˜ë¯€ë¡œ
        # ì´ ê²½ìš° lda_topicsë¥¼ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •í•˜ê³  ê±´ë„ˆëœë‹ˆë‹¤.
        if not tokenized_texts or all(len(tokens) == 0 for tokens in tokenized_texts):
            # LDAë¥¼ ëŒë¦´ ë¬¸ì¥ì´ ì—†ìœ¼ë¯€ë¡œ, ë¹ˆ ê²°ê³¼ë¥¼ í• ë‹¹
            lda_topics = []
            wc_filenames = []
        else:
            # (3) Gensim Dictionary + Corpus(BOW) ìƒì„±
            dictionary = corpora.Dictionary(tokenized_texts)
            corpus = [dictionary.doc2bow(tokens) for tokens in tokenized_texts]

            # (4) LDA ëª¨ë¸ í•™ìŠµ (í† í”½ ìˆ˜Â·íŒ¨ìŠ¤ ìˆ˜ëŠ” í•„ìš”ì— ë§ê²Œ ì¡°ì ˆ ê°€ëŠ¥)
            lda_model = LdaModel(
                corpus=corpus,
                id2word=dictionary,
                num_topics=5,
                passes=10,
                random_state=42
            )

            # (5) í† í”½ ê²°ê³¼ ì¶”ì¶œ
            topics = lda_model.print_topics(num_words=5)
            lda_topics = []
            for idx, topic_string in topics:
                lda_topics.append({
                    "topic_id": idx + 1,    # í™”ë©´ì— ë³´ì—¬ì¤„ ë•ŒëŠ” 1ë¶€í„° ì‹œì‘
                    "keywords": topic_string
                })
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì½”ë“œ ì‹œì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        # ì›Œë“œí´ë¼ìš°ë“œë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ (static/wordclouds)
        wc_folder = os.path.join(app.config['GRAPH_FOLDER'], 'wordclouds')
        os.makedirs(wc_folder, exist_ok=True)

        # í•œê¸€ í°íŠ¸ ê²½ë¡œ: í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.
        # macOS ì˜ˆì‹œ: '/Library/Fonts/AppleGothic.ttf'
        # Windows ì˜ˆì‹œ: 'C:/Windows/Fonts/malgun.ttf'
        FONT_PATH = '/Library/Fonts/AppleGothic.ttf'

        # í† í”½ ê°œìˆ˜ (lda_model.num_topics) ë§Œí¼ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        num_topics = lda_model.num_topics
        wc_filenames = []  # ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ì°¨ë¡€ëŒ€ë¡œ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

        for topic_id in range(min(3, num_topics)):
            # ê° í† í”½ì—ì„œ ìƒìœ„ 30ê°œ ë‹¨ì–´+ê°€ì¤‘ì¹˜ ì¶”ì¶œ
            topic_terms = lda_model.show_topic(topic_id, topn=30)
            # topic_terms ì˜ˆ: [('ì •ì‚°', 0.05), ('ìš”ì²­', 0.03), â€¦]

            # ì›Œë“œí´ë¼ìš°ë“œì— ë„˜ê¸¸ ë¹ˆë„ ì‚¬ì „ ìƒì„±
            freq_dict = { word: float(weight) for word, weight in topic_terms }

            # WordCloud ê°ì²´ ìƒì„± ë° ë¹ˆë„ ì‚¬ì „ ë°˜ì˜
            wc = WordCloud(
                background_color='white',
                font_path=FONT_PATH,
                width=800,
                height=400
            ).generate_from_frequencies(freq_dict)

            # íŒŒì¼ëª…: topic_1.png, topic_2.png, â€¦ í˜•íƒœ
            file_name = f"topic_{topic_id+1}.png"
            save_path = os.path.join(wc_folder, file_name)

            # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
            wc.to_file(save_path)

            # í…œí”Œë¦¿ì— ë„˜ê²¨ì¤„ ë•ŒëŠ” 'wordclouds/topic_1.png' ê²½ë¡œë¡œ ì‚¬ìš©
            wc_filenames.append(os.path.join('wordclouds', file_name))
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì½”ë“œ ë â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # âœ… ìµœì¢… ì§„í–‰ë¥  100%ë¡œ ì„¤ì • (ì™„ë£Œ í‘œì‹œ)
        progress_data["progress"] = 100

    return render_template('index.html',
                           table_html=table_html,
                           top_styles=top_styles,
                           graph_filename=graph_filename,
                           speaker_stats=speaker_stats,
                           lda_topics = lda_topics,
                           wc_filenames = wc_filenames)
    
# âœ… ì§„í–‰ë¥  ì¡°íšŒìš© route ì¶”ê°€
@app.route('/progress', methods=['GET'])
def progress():
    return {"progress": progress_data["progress"]}

# ì‹¤í–‰
if __name__ == '__main__':
    app.run(debug=True)