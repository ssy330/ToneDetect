{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ ì„¤ì •\n",
    "ADAPTER_PATH = \"../Models/ToneDetect_adapter\"  # adapterë§Œ ìˆìœ¼ë©´ ë¨\n",
    "BASE_MODEL_NAME = \"beomi/kcbert-base\"          # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ base model ì´ë¦„\n",
    "\n",
    "# âœ… tokenizerëŠ” base model ê¸°ì¤€\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "# âœ… base model â†’ adapter ì—°ê²°\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=5)\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "model.eval()\n",
    "\n",
    "# âœ… ë¼ë²¨ ë§¤í•‘ ì •ì˜\n",
    "label_map = {\n",
    "    0: \"chat_emoticon(ì´ëª¨í‹°ì½˜ ìì£¼ ì“°ëŠ” ë§íˆ¬)\",\n",
    "    1: \"elder_speech(ì–´ë¥´ì‹  ë§íˆ¬)\",\n",
    "    2: \"formal(ê²©ì‹ìˆëŠ” ë§íˆ¬)\",\n",
    "    3: \"informal(ì¹œê·¼í•œ ë§íˆ¬)\",\n",
    "    4: \"soft_polite(ë¶€ë“œëŸ½ê³  ìƒëƒ¥í•œ ë§íˆ¬)\"\n",
    "}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# âœ… ì‚¬ìš©ìë³„ ë©”ì‹œì§€ ë¶„ë¦¬\n",
    "def parse_chat_file(filename):\n",
    "    user_messages = defaultdict(list)\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if re.match(r\"^-{5,}\", line) or re.match(r\"^\\d{4}ë…„ \\d{1,2}ì›” \\d{1,2}ì¼\", line):\n",
    "                continue\n",
    "            match = re.match(r\"\\[([^]]+)] \\[([^]]+)] (.+)\", line)\n",
    "            if match:\n",
    "                user, time, message = match.groups()\n",
    "                user_messages[user].append(message)\n",
    "    return user_messages\n",
    "\n",
    "# âœ… ë¬¸ì¥ í•˜ë‚˜ ì˜ˆì¸¡\n",
    "def predict_style(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        pred_class = torch.argmax(logits, dim=1).item()\n",
    "    return pred_class\n",
    "\n",
    "# âœ… ì „ì²´ ì±„íŒ… ì˜ˆì¸¡ ë¶„ì„\n",
    "def analyze_chat_styles_with_messages(filename):\n",
    "    user_messages = parse_chat_file(filename)\n",
    "    result_summary = {}\n",
    "    result_sentences = {}\n",
    "\n",
    "    for user, messages in user_messages.items():\n",
    "        style_counts = defaultdict(int)\n",
    "        style_messages = defaultdict(list)\n",
    "        for message in messages:\n",
    "            predicted_class = predict_style(message)\n",
    "            style_name = label_map[predicted_class]\n",
    "            style_counts[style_name] += 1\n",
    "            style_messages[style_name].append(message)\n",
    "        result_summary[user] = dict(style_counts)\n",
    "        result_sentences[user] = dict(style_messages)\n",
    "\n",
    "    return result_summary, result_sentences\n",
    "\n",
    "# âœ… ì‚¬ìš©ì ë§íˆ¬ ë³„ ë¬¸ì¥ ë³´ê¸°\n",
    "def get_sentences_by_style(user, style_name, result_sentences):\n",
    "    if user not in result_sentences:\n",
    "        print(f\"[ì˜¤ë¥˜] ì‚¬ìš©ì '{user}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    if style_name not in result_sentences[user]:\n",
    "        print(f\"[ì•Œë¦¼] '{user}'ëŠ” '{style_name}' ë§íˆ¬ë¡œ ë¶„ë¥˜ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "    print(f\"\\n[{user}]ì˜ '{style_name}' ì˜ˆì¸¡ ë¬¸ì¥ë“¤:\")\n",
    "    for idx, sentence in enumerate(result_sentences[user][style_name], 1):\n",
    "        print(f\"{idx}. {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š [ì „ì²´ ì‚¬ìš©ìë³„ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½]\n",
      "\n",
      "ğŸ§‘ ê¹€ì†Œì—°\n",
      "  - elder_speech(ì–´ë¥´ì‹  ë§íˆ¬): 2ë¬¸ì¥\n",
      "  - soft_polite(ë¶€ë“œëŸ½ê³  ìƒëƒ¥í•œ ë§íˆ¬): 3ë¬¸ì¥\n",
      "  - chat_emoticon(ì´ëª¨í‹°ì½˜ ìì£¼ ì“°ëŠ” ë§íˆ¬): 16ë¬¸ì¥\n",
      "  - informal(ì¹œê·¼í•œ ë§íˆ¬): 3ë¬¸ì¥\n",
      "  - formal(ê²©ì‹ìˆëŠ” ë§íˆ¬): 2ë¬¸ì¥\n",
      "\n",
      "ğŸ§‘ ìœ ì •ìœ ì •\n",
      "  - chat_emoticon(ì´ëª¨í‹°ì½˜ ìì£¼ ì“°ëŠ” ë§íˆ¬): 22ë¬¸ì¥\n",
      "  - elder_speech(ì–´ë¥´ì‹  ë§íˆ¬): 1ë¬¸ì¥\n",
      "  - informal(ì¹œê·¼í•œ ë§íˆ¬): 5ë¬¸ì¥\n",
      "  - formal(ê²©ì‹ìˆëŠ” ë§íˆ¬): 2ë¬¸ì¥\n",
      "  - soft_polite(ë¶€ë“œëŸ½ê³  ìƒëƒ¥í•œ ë§íˆ¬): 3ë¬¸ì¥\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# âœ… ì‹¤í–‰ ì˜ˆì‹œ\n",
    "filename = \"../datasets/KakaoTalk_20250515_0053_22_930_ìœ ì •ìœ ì •.txt\"\n",
    "result_summary, result_sentences = analyze_chat_styles_with_messages(filename)\n",
    "\n",
    "# âœ… ì‚¬ìš©ìë³„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "print(\"\\nğŸ“Š [ì „ì²´ ì‚¬ìš©ìë³„ ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½]\")\n",
    "for user, style_count in result_summary.items():\n",
    "    print(f\"\\nğŸ§‘ {user}\")\n",
    "    for style, count in style_count.items():\n",
    "        print(f\"  - {style}: {count}ë¬¸ì¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ê¹€ì†Œì—°]ì˜ 'soft_polite(ë¶€ë“œëŸ½ê³  ìƒëƒ¥í•œ ë§íˆ¬)' ì˜ˆì¸¡ ë¬¸ì¥ë“¤:\n",
      "1. í•˜ë˜ê²Œ ì•ˆëë‚¬ì–´.. ì˜ë¦¬..\n",
      "2. ì•„ í— ë‚˜ ì˜¤ëŠ˜ ê³„ì† ìë²„ë ¸ë„¤.. ì§€ê¸ˆë¶€í„° í•˜ê³  ìˆì„ê²Œã… ã… \n",
      "3. ë‚˜ë„ ê³„ì† í•´ë³´ê³  ìˆì–´..!!\n",
      "\n",
      "[ìœ ì •ìœ ì •]ì˜ 'chat_emoticon(ì´ëª¨í‹°ì½˜ ìì£¼ ì“°ëŠ” ë§íˆ¬)' ì˜ˆì¸¡ ë¬¸ì¥ë“¤:\n",
      "1. í—‰ ì•„ëƒì•„ëƒ!!?\n",
      "2. ì—¬ìœ ìˆê²Œ ì™€ ã…ã…\n",
      "3. 30ë¶„ì¯¤ ë³´ìŸ!!\n",
      "4. í—‰ !!! ë‚˜ëŠ” ë²„ìŠ¤ê°€ ëŠ¦ì–´ì ¸ì„œ ê³§ íƒˆ ê±° ê°™ì•„...ã…ã…\n",
      "5. ê·¸ ìŠ¤íƒ€ë²…ìŠ¤ ê°ˆê¹Œ í•˜ëŠ”ë° ì–´ë•Œ??\n",
      "6. [ë„¤ì´ë²„ ì§€ë„]\n",
      "7. ì›…ì›… ê³ ë§ˆì–´ğŸ¥°ğŸ¥°\n",
      "8. ì–¸ëŠ¥ ê°ˆê²Œ!!!\n",
      "9. ë‚˜ ë‚´ë ¸ì˜¤ ã…ã…\n",
      "10. ìŠ¤ë²… ì•ì´ì–‘??\n",
      "11. ê±´ë„ˆí¸ì— íˆ¬ì¸ ìˆëŠ”ë° ê°€ë³¼ê¹Œ???\n",
      "12. ê±´ë„ˆ ì˜¬ë­?????\n",
      "13. ì•Œì¨ğŸ˜†ğŸ˜†\n",
      "14. https://www.genspark.ai/\n",
      "15. ì–¸ë‹ˆ ì§„ì§œ ë„ˆë¬´ ê³ ìƒ¹í•´ì¨... ì¡°ì‹¬íˆ ì˜ ë“¤ì–´ê°€êµ¬ í™”ìšœì— ë³´ìğŸ˜‚ğŸ˜‚â¤\n",
      "16. ì˜¤ì¼€ì´!! ê³ ë§ˆì›¡ğŸ¥°\n",
      "17. ì–¸ë‹ˆ !! ë‚˜ ëŒ€ë³¸ ë‹¤ì¼ì–´ ã…ã…\n",
      "18. ì˜¤ ì§„ì§œ??? ì¡°ì•„ì¡°ì•„ ê³ ë§ˆì–´ ã…ã…ã…ã…\n",
      "19. ë‚´ì¼ ì´ëŒ€ë¡œ í• ê²¡ ã…ã…\n",
      "20. ì–¸ë‹ˆ í˜¹ì‹œ ì½”ë“œ ë¶„ì„ ì–¼ë§ˆë‚˜ í–ˆì–´?? ë‚´ê°€ ì•„ì§ í•™êµë¼ì„œ ì§‘ ê°€ì„œ í•  ìˆ˜ ìˆì„ ê±° ê°™ì•„â€¦.\n",
      "21. ì—...? ì§„ì§œ ê´œì°®ê²Œì¨?? ë‚´ ì˜¤ì›€ì´ í•„ìš”ã…˜ë©´ ê¼­ ë§í•´ì¤˜!!!!!\n",
      "22. ì´ë”°ë³´ìŸ,, ì§„ì§œ ê³ ë§™êµ¬ ìˆ˜ê³ í•´ì¨ğŸ˜‚â¤â¤\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# âœ… ì›í•˜ëŠ” ì˜ˆì¸¡ ë¬¸ì¥ ë³´ê¸°\n",
    "get_sentences_by_style(\"ê¹€ì†Œì—°\", \"soft_polite(ë¶€ë“œëŸ½ê³  ìƒëƒ¥í•œ ë§íˆ¬)\", result_sentences)\n",
    "get_sentences_by_style(\"ìœ ì •ìœ ì •\", \"chat_emoticon(ì´ëª¨í‹°ì½˜ ìì£¼ ì“°ëŠ” ë§íˆ¬)\", result_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì¼ ì…ë ¥ ë°›ê¸° (KakaoTalk_20250511_1625_29_658_ìœ ì •ìœ ì •)\n",
    "\n",
    "# íŒŒì¼ì˜ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ìŒ\n",
    "# --------------- 2025ë…„ 3ì›” 19ì¼ ìˆ˜ìš”ì¼ ---------------\n",
    "# [ìœ ì •ìœ ì •] [ì˜¤í›„ 2:02] ì–¸ë‹ˆ í˜¹ì‹œ ëë‚¬ì–´??\n",
    "# [ê¹€ì†Œì—°] [ì˜¤í›„ 2:03] ì•„ì§ ìˆ˜ì—…ì¤‘ã… ã… \n",
    "# [ìœ ì •ìœ ì •] [ì˜¤í›„ 2:03] í—‰!!\n",
    "# [ìœ ì •ìœ ì •] [ì˜¤í›„ 2:03] ë¨¼ì € ê°€ê³  ìˆì„ê²Œ ã…ã…\n",
    "# [ê¹€ì†Œì—°] [ì˜¤í›„ 2:03] ì›…ì›…~\n",
    "# [ìœ ì •ìœ ì •] [ì˜¤í›„ 2:08] ì˜¤ë¥¸ìª½ ì•ì—ì„œ ë‘ë²ˆì§¸ ì•ˆìª½ìœ¼ë¡œ ìë¦¬ ì¡ì•„ë†”ì“°ğŸ˜†â¤\n",
    "# [ê¹€ì†Œì—°] [ì˜¤í›„ 2:16] ë‚˜ ë°©ê¸ˆ ëë‚˜ì„œ ê°€ëŠ” ì¤‘!\n",
    "# --------------- 2025ë…„ 3ì›” 26ì¼ ìˆ˜ìš”ì¼ ---------------\n",
    "# [ìœ ì •ìœ ì •] [ì˜¤í›„ 2:16] ã…ã… ì–¸ë‹ˆ ë¯¸ì•ˆ... ë˜ ì•ìë¦¬ì–Œ...\n",
    "# [ìœ ì •ìœ ì •] [ì˜¤í›„ 2:16] ì €ë²ˆì— ì•‰ì•˜ë˜ ê·¸ ìë¦¬...^^\n",
    "\n",
    "# ë‚ ì§œ ë¶€ë¶„ ë²„ë¦¬ê¸°\n",
    "# ì´ë¦„ ë³„ë¡œ ë¬¸ì¥ ëª¨ìœ¼ê¸°\n",
    "\n",
    "# ê¸°ì¡´ ì½”ë“œì™€ í•©ì¹˜ê¸°\n",
    "# ìµœì¢… ê²°ê³¼ëŠ” ì´ë¦„ ë‹¹ ê° í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡ëœ ë¬¸ì¥ ê°¯ìˆ˜\n",
    "# ì˜ˆì‹œ)\n",
    "# ê¹€ì†Œì—° -> {ë¡œë´‡ ë§íˆ¬ (android): 5, ì—°ì¥ì ë§íˆ¬(azae):3 ...}\n",
    "# ìœ ì •ìœ ì • -> {ë¡œë´‡ ë§íˆ¬ (android): 2, ì—°ì¥ì ë§íˆ¬(azae):7 ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ëœ í´ë˜ìŠ¤: 6\n",
      "ì˜ˆì¸¡ëœ ë§íˆ¬: ì¡´ëŒ“ë§ (formal)\n"
     ]
    }
   ],
   "source": [
    "text = \"ì•ˆë…•í•˜ì„¸ìš”\"  # ì˜ˆì¸¡í•˜ê³  ì‹¶ì€ ë¬¸ì¥\n",
    "\n",
    "# ì…ë ¥ í† í¬ë‚˜ì´ì¦ˆ\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)   \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "label_map = {\n",
    "    0: \"chat_emoticon\",\n",
    "    1: \"elder_speech\",\n",
    "    2: \"formal\",\n",
    "    3: \"informal\",\n",
    "    4: \"soft_polite\"\n",
    "}\n",
    "\n",
    "print(\"ì˜ˆì¸¡ëœ í´ë˜ìŠ¤:\", predicted_class)\n",
    "print(\"ì˜ˆì¸¡ëœ ë§íˆ¬:\", label_map[predicted_class])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
