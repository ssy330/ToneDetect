{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# 🔧 경로 설정\n",
    "ADAPTER_PATH = \"../Models/ToneDetect_adapter\"  # adapter만 있으면 됨\n",
    "BASE_MODEL_NAME = \"beomi/kcbert-base\"          # 학습 시 사용한 base model 이름\n",
    "\n",
    "# ✅ tokenizer는 base model 기준\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "# ✅ base model → adapter 연결\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL_NAME, num_labels=5)\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "model.eval()\n",
    "\n",
    "# ✅ 라벨 매핑 정의\n",
    "label_map = {\n",
    "    0: \"chat_emoticon(이모티콘 자주 쓰는 말투)\",\n",
    "    1: \"elder_speech(어르신 말투)\",\n",
    "    2: \"formal(격식있는 말투)\",\n",
    "    3: \"informal(친근한 말투)\",\n",
    "    4: \"soft_polite(부드럽고 상냥한 말투)\"\n",
    "}\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# ✅ 사용자별 메시지 분리\n",
    "def parse_chat_file(filename):\n",
    "    user_messages = defaultdict(list)\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if re.match(r\"^-{5,}\", line) or re.match(r\"^\\d{4}년 \\d{1,2}월 \\d{1,2}일\", line):\n",
    "                continue\n",
    "            match = re.match(r\"\\[([^]]+)] \\[([^]]+)] (.+)\", line)\n",
    "            if match:\n",
    "                user, time, message = match.groups()\n",
    "                user_messages[user].append(message)\n",
    "    return user_messages\n",
    "\n",
    "# ✅ 문장 하나 예측\n",
    "def predict_style(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        pred_class = torch.argmax(logits, dim=1).item()\n",
    "    return pred_class\n",
    "\n",
    "# ✅ 전체 채팅 예측 분석\n",
    "def analyze_chat_styles_with_messages(filename):\n",
    "    user_messages = parse_chat_file(filename)\n",
    "    result_summary = {}\n",
    "    result_sentences = {}\n",
    "\n",
    "    for user, messages in user_messages.items():\n",
    "        style_counts = defaultdict(int)\n",
    "        style_messages = defaultdict(list)\n",
    "        for message in messages:\n",
    "            predicted_class = predict_style(message)\n",
    "            style_name = label_map[predicted_class]\n",
    "            style_counts[style_name] += 1\n",
    "            style_messages[style_name].append(message)\n",
    "        result_summary[user] = dict(style_counts)\n",
    "        result_sentences[user] = dict(style_messages)\n",
    "\n",
    "    return result_summary, result_sentences\n",
    "\n",
    "# ✅ 사용자 말투 별 문장 보기\n",
    "def get_sentences_by_style(user, style_name, result_sentences):\n",
    "    if user not in result_sentences:\n",
    "        print(f\"[오류] 사용자 '{user}'를 찾을 수 없습니다.\")\n",
    "        return\n",
    "    if style_name not in result_sentences[user]:\n",
    "        print(f\"[알림] '{user}'는 '{style_name}' 말투로 분류된 문장이 없습니다.\")\n",
    "        return\n",
    "    print(f\"\\n[{user}]의 '{style_name}' 예측 문장들:\")\n",
    "    for idx, sentence in enumerate(result_sentences[user][style_name], 1):\n",
    "        print(f\"{idx}. {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 [전체 사용자별 예측 결과 요약]\n",
      "\n",
      "🧑 김소연\n",
      "  - elder_speech(어르신 말투): 2문장\n",
      "  - soft_polite(부드럽고 상냥한 말투): 3문장\n",
      "  - chat_emoticon(이모티콘 자주 쓰는 말투): 16문장\n",
      "  - informal(친근한 말투): 3문장\n",
      "  - formal(격식있는 말투): 2문장\n",
      "\n",
      "🧑 유정유정\n",
      "  - chat_emoticon(이모티콘 자주 쓰는 말투): 22문장\n",
      "  - elder_speech(어르신 말투): 1문장\n",
      "  - informal(친근한 말투): 5문장\n",
      "  - formal(격식있는 말투): 2문장\n",
      "  - soft_polite(부드럽고 상냥한 말투): 3문장\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ 실행 예시\n",
    "filename = \"../datasets/KakaoTalk_20250515_0053_22_930_유정유정.txt\"\n",
    "result_summary, result_sentences = analyze_chat_styles_with_messages(filename)\n",
    "\n",
    "# ✅ 사용자별 결과 요약 출력\n",
    "print(\"\\n📊 [전체 사용자별 예측 결과 요약]\")\n",
    "for user, style_count in result_summary.items():\n",
    "    print(f\"\\n🧑 {user}\")\n",
    "    for style, count in style_count.items():\n",
    "        print(f\"  - {style}: {count}문장\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[김소연]의 'soft_polite(부드럽고 상냥한 말투)' 예측 문장들:\n",
      "1. 하던게 안끝났어.. 쏘리..\n",
      "2. 아 헐 나 오늘 계속 자버렸네.. 지금부터 하고 있을게ㅠㅠ\n",
      "3. 나도 계속 해보고 있어..!!\n",
      "\n",
      "[유정유정]의 'chat_emoticon(이모티콘 자주 쓰는 말투)' 예측 문장들:\n",
      "1. 헉 아냐아냐!!?\n",
      "2. 여유있게 와 ㅎㅎ\n",
      "3. 30분쯤 보쟝!!\n",
      "4. 헉 !!! 나는 버스가 늦어져서 곧 탈 거 같아...ㅎㅎ\n",
      "5. 그 스타벅스 갈까 하는데 어때??\n",
      "6. [네이버 지도]\n",
      "7. 웅웅 고마어🥰🥰\n",
      "8. 언능 갈게!!!\n",
      "9. 나 내렸오 ㅎㅎ\n",
      "10. 스벅 앞이양??\n",
      "11. 건너편에 투썸 있는데 가볼까???\n",
      "12. 건너 올랭?????\n",
      "13. 알써😆😆\n",
      "14. https://www.genspark.ai/\n",
      "15. 언니 진짜 너무 고샹해써... 조심히 잘 들어가구 화욜에 보자😂😂❤\n",
      "16. 오케이!! 고마웡🥰\n",
      "17. 언니 !! 나 대본 다썼어 ㅎㅎ\n",
      "18. 오 진짜??? 조아조아 고마어 ㅎㅎㅎㅎ\n",
      "19. 내일 이대로 할겡 ㅎㅎ\n",
      "20. 언니 혹시 코드 분석 얼마나 했어?? 내가 아직 학교라서 집 가서 할 수 있을 거 같아….\n",
      "21. 에...? 진짜 괜찮게써?? 내 오움이 필요ㅘ면 꼭 말해줘!!!!!\n",
      "22. 이따보쟝,, 진짜 고맙구 수고해써😂❤❤\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ✅ 원하는 예측 문장 보기\n",
    "get_sentences_by_style(\"김소연\", \"soft_polite(부드럽고 상냥한 말투)\", result_sentences)\n",
    "get_sentences_by_style(\"유정유정\", \"chat_emoticon(이모티콘 자주 쓰는 말투)\", result_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 입력 받기 (KakaoTalk_20250511_1625_29_658_유정유정)\n",
    "\n",
    "# 파일의 형식은 아래와 같음\n",
    "# --------------- 2025년 3월 19일 수요일 ---------------\n",
    "# [유정유정] [오후 2:02] 언니 혹시 끝났어??\n",
    "# [김소연] [오후 2:03] 아직 수업중ㅠㅠ\n",
    "# [유정유정] [오후 2:03] 헉!!\n",
    "# [유정유정] [오후 2:03] 먼저 가고 있을게 ㅎㅎ\n",
    "# [김소연] [오후 2:03] 웅웅~\n",
    "# [유정유정] [오후 2:08] 오른쪽 앞에서 두번째 안쪽으로 자리 잡아놔쓰😆❤\n",
    "# [김소연] [오후 2:16] 나 방금 끝나서 가는 중!\n",
    "# --------------- 2025년 3월 26일 수요일 ---------------\n",
    "# [유정유정] [오후 2:16] ㅎㅎ 언니 미안... 또 앞자리얌...\n",
    "# [유정유정] [오후 2:16] 저번에 앉았던 그 자리...^^\n",
    "\n",
    "# 날짜 부분 버리기\n",
    "# 이름 별로 문장 모으기\n",
    "\n",
    "# 기존 코드와 합치기\n",
    "# 최종 결과는 이름 당 각 클래스로 예측된 문장 갯수\n",
    "# 예시)\n",
    "# 김소연 -> {로봇 말투 (android): 5, 연장자 말투(azae):3 ...}\n",
    "# 유정유정 -> {로봇 말투 (android): 2, 연장자 말투(azae):7 ...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측된 클래스: 6\n",
      "예측된 말투: 존댓말 (formal)\n"
     ]
    }
   ],
   "source": [
    "text = \"안녕하세요\"  # 예측하고 싶은 문장\n",
    "\n",
    "# 입력 토크나이즈\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)   \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "label_map = {\n",
    "    0: \"chat_emoticon\",\n",
    "    1: \"elder_speech\",\n",
    "    2: \"formal\",\n",
    "    3: \"informal\",\n",
    "    4: \"soft_polite\"\n",
    "}\n",
    "\n",
    "print(\"예측된 클래스:\", predicted_class)\n",
    "print(\"예측된 말투:\", label_map[predicted_class])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
